{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import os \n",
    "import zipfile \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 \n",
    "from tensorflow.keras.optimizers import RMSprop \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [128, 128]\n",
    "\n",
    "train_path = 'data/Train'\n",
    "valid_path = 'data/Test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 214603 images belonging to 108 classes.\n"
     ]
    }
   ],
   "source": [
    "#training data directory and parameteres\n",
    "trainDataGen = ImageDataGenerator(\n",
    "                    rotation_range = 5,\n",
    "                    width_shift_range = 0.1,\n",
    "                    height_shift_range = 0.1,\n",
    "                    rescale = 1.0/255,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = False,\n",
    "                    fill_mode = 'nearest',\n",
    "                )\n",
    "\n",
    "testDataGen = ImageDataGenerator(rescale=1.0/255,)\n",
    "\n",
    "\n",
    "train_gen = trainDataGen.flow_from_directory(\n",
    "                    \"data/Train\",\n",
    "                    target_size=(128, 128),\n",
    "                    class_mode=\"categorical\",\n",
    "                    batch_size=64\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32400 images belonging to 108 classes.\n"
     ]
    }
   ],
   "source": [
    "#validation data directory and parameteres\n",
    "val_gen = testDataGen.flow_from_directory(\n",
    "                    \"data/Test\",\n",
    "                    target_size=(128, 128),\n",
    "                    class_mode=\"categorical\",\n",
    "                    batch_size=64\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building base model\n",
    "base_model = InceptionV3(input_shape = IMAGE_SIZE + [3],  \n",
    "                                include_top = False,  \n",
    "                                weights = 'imagenet') \n",
    "for layer in base_model.layers: \n",
    "  layer.trainable = False\n",
    "  \n",
    "#stop training is model accuracy reached 99% \n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "  def on_epoch_end(self, epoch, logs={}): \n",
    "    if(logs.get('acc')>0.99): \n",
    "      self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code \n",
    "x = layers.Flatten()(base_model.output) \n",
    "\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(256,activation='relu')(x) \n",
    "x = layers.Dropout(0.1)(x)  #dropout is decreased after observation of resutls on dataset\n",
    "x = layers.BatchNormalization()(x)\n",
    "\n",
    "x = layers.Dense(108, activation='softmax')(x)            \n",
    "  \n",
    "model = Model( base_model.input, x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer = opt,loss = 'categorical_crossentropy',metrics = ['acc']) # was using binary before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if no change in validation loss - learning rate will be decreased\n",
    "anne = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\n",
    "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3353/3353 [==============================] - 1502s 448ms/step - loss: 1.2727 - acc: 0.5959 - val_loss: 0.8233 - val_acc: 0.7137\n",
      "Epoch 2/30\n",
      "3353/3353 [==============================] - 1675s 499ms/step - loss: 0.9221 - acc: 0.6831 - val_loss: 0.6909 - val_acc: 0.7505\n",
      "Epoch 3/30\n",
      "3353/3353 [==============================] - 1709s 510ms/step - loss: 0.8324 - acc: 0.7089 - val_loss: 0.6584 - val_acc: 0.7559\n",
      "Epoch 4/30\n",
      "3353/3353 [==============================] - 1669s 498ms/step - loss: 0.7801 - acc: 0.7243 - val_loss: 0.6117 - val_acc: 0.7727\n",
      "Epoch 5/30\n",
      "3353/3353 [==============================] - 1651s 492ms/step - loss: 0.7420 - acc: 0.7363 - val_loss: 0.5865 - val_acc: 0.7794\n",
      "Epoch 6/30\n",
      "3353/3353 [==============================] - 1726s 515ms/step - loss: 0.7144 - acc: 0.7442 - val_loss: 0.5736 - val_acc: 0.7845\n",
      "Epoch 7/30\n",
      "3353/3353 [==============================] - 1662s 496ms/step - loss: 0.6894 - acc: 0.7501 - val_loss: 0.5575 - val_acc: 0.7912\n",
      "Epoch 8/30\n",
      "3353/3353 [==============================] - 1677s 500ms/step - loss: 0.6705 - acc: 0.7562 - val_loss: 0.5518 - val_acc: 0.7915\n",
      "Epoch 9/30\n",
      "3353/3353 [==============================] - 1642s 490ms/step - loss: 0.6574 - acc: 0.7603 - val_loss: 0.5613 - val_acc: 0.7870\n",
      "Epoch 10/30\n",
      "3353/3353 [==============================] - 1648s 491ms/step - loss: 0.6461 - acc: 0.7632 - val_loss: 0.5465 - val_acc: 0.7917\n",
      "Epoch 11/30\n",
      "3353/3353 [==============================] - 1628s 486ms/step - loss: 0.6324 - acc: 0.7674 - val_loss: 0.5484 - val_acc: 0.7905\n",
      "Epoch 12/30\n",
      "3353/3353 [==============================] - 1598s 476ms/step - loss: 0.6204 - acc: 0.7711 - val_loss: 0.5295 - val_acc: 0.7991\n",
      "Epoch 13/30\n",
      "3353/3353 [==============================] - 1629s 486ms/step - loss: 0.6117 - acc: 0.7735 - val_loss: 0.5164 - val_acc: 0.8029\n",
      "Epoch 14/30\n",
      "3353/3353 [==============================] - 1876s 559ms/step - loss: 0.6040 - acc: 0.7766 - val_loss: 0.5130 - val_acc: 0.8031\n",
      "Epoch 15/30\n",
      "3353/3353 [==============================] - 1597s 476ms/step - loss: 0.5993 - acc: 0.7772 - val_loss: 0.5224 - val_acc: 0.7979\n",
      "Epoch 16/30\n",
      "3353/3353 [==============================] - 1569s 468ms/step - loss: 0.5900 - acc: 0.7798 - val_loss: 0.5123 - val_acc: 0.8015\n",
      "Epoch 17/30\n",
      " 353/3353 [==>...........................] - ETA: 24:58 - loss: 0.5696 - acc: 0.7871"
     ]
    }
   ],
   "source": [
    "#fitting the model  \n",
    "incep = model.fit( \n",
    "            train_gen, \n",
    "            validation_data = val_gen, \n",
    "            steps_per_epoch = 3353, \n",
    "            epochs = 30, \n",
    "            validation_steps = 506) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "model.save(\"IncepModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the graph\n",
    "%matplotlib inline\n",
    "accu=incep.history['acc']\n",
    "val_acc=incep.history['val_acc']\n",
    "loss=incep.history['loss']\n",
    "val_loss=incep.history['val_loss']\n",
    "\n",
    "epochs=range(len(accu)) #No. of epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,accu,'r',label='Training Accuracy')\n",
    "plt.plot(epochs,val_acc,'g',label='Testing Accuracy')\n",
    "\n",
    "plt.savefig('training_accuracy_mix_incep.png')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Plot training and validation loss per epoch\n",
    "plt.plot(epochs,loss,'r',label='Training Loss')\n",
    "plt.plot(epochs,val_loss,'g',label='Testing Loss')\n",
    "\n",
    "plt.savefig('training_loss_mix_incep.png')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
